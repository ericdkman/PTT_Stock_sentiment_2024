import getpass
import os
import json
import pandas as pd
import functools
import operator
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_experimental.tools import PythonREPLTool 
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import END, StateGraph, START
from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser
from typing import Sequence, TypedDict, Annotated

def _set_if_undefined(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"Please provide your {var}")

# 設置環境變量
_set_if_undefined("OPENAI_API_KEY")
_set_if_undefined("OPENAI_ORGANIZATION")
_set_if_undefined("LANGCHAIN_API_KEY")
_set_if_undefined("TAVILY_API_KEY")

# Optional, add tracing in LangSmith
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Multi-agent Collaboration"

# 读取CSV文件
file_path = "ptt_stock_posts_num1.csv"
df = pd.read_csv(file_path)

# 预览数据
print(df.head())

# 定義工具
tavily_tool = TavilySearchResults(max_results=5)
python_repl_tool = PythonREPLTool() 

# 定義代理
def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="messages"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )
    agent = create_openai_tools_agent(llm, tools, prompt)
    executor = AgentExecutor(agent=agent, tools=tools)
    return executor

def agent_node(state, agent, name):
    # 獲取原始內容
    original_content = state.get("original_content", "")
    
    # 獲取之前的消息歷史
    previous_messages = state["messages"]
    
    # 根據 agent 的角色構建新的輸入消息
    if name == "Analysis_1":
        new_message = HumanMessage(content=f"Analyze the sentiment of the following content: {original_content}")
    else:  # Analysis_final
        previous_analysis = previous_messages[-1].content if previous_messages else ""
        new_message = HumanMessage(content=f"Given the following original content and previous analysis, provide a comprehensive financial sentiment analysis:\n\nOriginal content: {original_content}\n\nPrevious analysis: {previous_analysis}")
    
    # 將新消息添加到狀態中
    updated_state = {
        "messages": previous_messages + [new_message],
        "original_content": original_content
    }
    
    # 調用 agent
    result = agent.invoke(updated_state)
    
    # 返回更新後的狀態
    return {
        "messages": updated_state["messages"] + [HumanMessage(content=result["output"], name=name)],
        "original_content": original_content
    }
    
    

members = ["Analysis_1", "Analysis_final"]
system_prompt = (
    "You are a supervisor tasked with managing a conversation between the"
    " following workers: {members}. Given the following user request,"
    " respond with the worker to act next. Each worker will perform a"
    " task and respond with their results and status. When finished,"
    " respond with FINISH."
)
options = ["FINISH"] + members
function_def = {
    "name": "route",
    "description": "Select the next role.",
    "parameters": {
        "title": "routeSchema",
        "type": "object",
        "properties": {
            "next": {
                "title": "Next",
                "anyOf": [{"enum": options}],
            }
        },
        "required": ["next"],
    },
}
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        (
            "system",
            "Given the conversation above, who should act next?"
            " Or should we FINISH? Select one of: {options}",
        ),
    ]
).partial(options=str(options), members=", ".join(members))

llm = ChatOpenAI(model="gpt-4o")

supervisor_chain = (
    prompt
    | llm.bind_functions(functions=[function_def], function_call="route")
    | JsonOutputFunctionsParser()
)

class AgentState(TypedDict):
    messages: Sequence[BaseMessage]
    next: str
    original_content: str

research_agent = create_agent(llm, [tavily_tool], "You are a investor. Analyze the sentiment of the given financial content.")
research_node = functools.partial(agent_node, agent=research_agent, name="Analysis_1")

# code_agent = create_agent(llm,[python_repl_tool], "You may generate charts using matplotlib.")
# code_node = functools.partial(agent_node, agent=code_agent, name="Coder")

finance_sentiment_agent = create_agent(llm, [tavily_tool], "You are a financial sentiment analysis expert. Analyze the sentiment of the given financial content.")
finance_sentiment_node = functools.partial(agent_node, agent=finance_sentiment_agent, name="Analysis_final")

workflow = StateGraph(AgentState)
workflow.add_node("Analysis_1", research_node) 
workflow.add_node("Analysis_final", finance_sentiment_node)
# workflow.add_node("Coder", code_node)
workflow.add_node("supervisor", supervisor_chain)

for member in members:
    workflow.add_edge(member, "supervisor")
conditional_map = {k: k for k in members}
conditional_map["FINISH"] = END
workflow.add_conditional_edges("supervisor", lambda x: x["next"], conditional_map)
workflow.add_edge(START, "supervisor")

graph = workflow.compile()

# 流式處理每篇文章
for index, row in df.iterrows():
    article_content = row['Content']
    
    # 創建 HumanMessage 對象
    input_message_content = HumanMessage(content=f"Analyze the sentiment of the following content: {article_content}")
    
    # 將消息對象包裝成字典格式
    messages_dict = {
        "messages": [input_message_content],  # 使用 "messages" 鍵
        "original_content": article_content
    }
    
    # 流式處理
    for s in graph.stream(messages_dict):
        if "__end__" not in s:
            print(s)
            print("----")

print('done')
